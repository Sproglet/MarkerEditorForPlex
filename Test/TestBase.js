// External dependencies
import fetch from 'node-fetch';
import { existsSync, writeFileSync, unlinkSync } from 'fs';
import { dirname, join } from 'path';
import { fileURLToPath } from 'url';

// Common-JS dependencies
import CreateDatabase from "../Server/CreateDatabase.cjs";

// Client/Server shared dependencies
import { ConsoleLog } from "../Shared/ConsoleLog.js";

// Server/test dependencies/typedefs
import TestHelpers from "./TestHelpers.js";
import { run as mainRun, ServerState, getState } from "../Server/PlexIntroEditor.js";
/** @typedef {!import('../Server/CreateDatabase.cjs').SqliteDatabase} SqliteDatabase */

// Separate log for testing, since we want to suppress
// most server messages, but have more test details
const TestLog = new ConsoleLog();
TestLog.setLevel(ConsoleLog.Level.Tmi);
TestLog.setDarkConsole(1);

/**
 * Base class for integration tests, containing common test configuration logic.
 */
class TestBase {
    /** @type {method[]} */
    testMethods = [];

    static root = join(dirname(dirname(fileURLToPath(import.meta.url))), 'Test');
    static testConfig = join(TestBase.root, 'testConfig.json');
    static testDbPath = join(TestBase.root, 'plexDbTest.db');

    /** @type {SqliteDatabase} */
    testDb = null;

    constructor() {
        TestLog.tmi('TestBase Constructor');
    }

    /** The name of this test class. Should be overridden by implementing classes. */
    className() { return 'TestBase'; }

    /**
     * Base method to setup the test config. Implementing classes can override this
     * to provide custom settings. */
    setupConfig() { this.createConfig({}); }

    /**
     * Static helper method that attempts to delete the autogenerated test database/config */
    static Cleanup() {
        if (existsSync(TestBase.testDbPath)) {
            TestLog.tmi(`TestBase::Cleanup - Deleting old database`);
            unlinkSync(TestBase.testDbPath);
        }

        if (existsSync(TestBase.testConfig)) {
            TestLog.tmi(`TestBase::Cleanup - Deleting old config`)
            unlinkSync(TestBase.testConfig);
        }
    }

    /**
     * Initiate the run for this test class, setting up the database and config file before
     * running through the test methods. */
    async runTests() {
        TestBase.Cleanup();

        return new Promise(function(resolve, reject) {
            this.testDb = CreateDatabase(TestBase.testDbPath, true /*allowCreate*/, async (err) => {
                if (err) {
                    TestLog.error(err, `Failed to create test database, cannot run ${this.className()}!`);
                    reject(err);
                }
    
                await this.setupPlexDbTestTables();
    
                this.setupConfig();
                this.startService().then(function() {
                    resolve(this.run());
                }.bind(this));
            });
        }.bind(this));
    }

    /**
     * Writes the test configuration to disk.
     * @param {{}} overrides Dictionary of custom configuration values to set, if any. */
    createConfig(overrides) {
        const td = (field, value, force=false) => { if (!overrides.hasOwnProperty(field) || force) { overrides[field] = value; } };
        const tf = (feature, value) => { if (!overrides.features) { overrides.features = {}; } if (!overrides.features.hasOwnProperty(feature)) { overrides.features[feature] = value; }};

        // Test defaults
        td('host', 'localhost', true);
        td('port', 3233, true);
        td('database', TestBase.testDbPath, true);
        td('logLevel', 'DarkWarn');

        // Good testing of preview thumbnails would require actual bif files and proper test db
        // entries that I don't want to deal with right now.
        tf('previewThumbnails', false);
        tf('autoOpen', false);

        // TODO: Test backup database as well
        tf('backupActions', false);

        writeFileSync(TestBase.testConfig, JSON.stringify(overrides))
    }

    /**
     * Starts the Plex Intro Editor. Expects to have been run via launch.json's "Run Tests"
     * configuration, which will pass in the right command line arguments to mainRun. */
    async startService() {
        if (getState() == ServerState.FirstBoot) {
            mainRun();
        } else {
            this.resume();
        }

        // This is terrible and should change, but it's midnight and I want to get a proof-of-concept up and running.
        // A callback registration system would probably be better.
        return new Promise(function(resolve, reject) {
            let interval = setInterval(function() {
                if (getState() == ServerState.Running) {
                    TestLog.tmi(`Server started, running tests...`);
                    clearInterval(interval);
                    interval = -1;
                    resolve();
                }
            }, 50);

            setTimeout(function() {
                if (interval != -1) {
                    clearInterval(interval);
                    TestLog.error(`Server did not start within 5 seconds, that shouldn't happen!`);
                    reject();
                }
            }, 5000);
        });
    }

    /**
     * Run all available test methods for this class. */
    async run() {
        TestLog.info(`Running tests for ${this.className()}`);
        let successCount = 0;
        let failureCount = 0;
        for (const method of this.testMethods) {
            await this.resetState();
            await this.resume();
            let success = true;
            let response = '';
            try {
                await method.bind(this)();
            } catch (ex) {
                success = false;
                response = ex.message;
            }

            TestLog.verbose(`\t[${method.name}]: ${success ? 'PASSED' : 'FAILED'}`);
            if (!success) {
                TestLog.verbose(`\t\t${response}`);
            }

            success ? ++successCount : ++failureCount;
            await this.suspend();
        }

        TestLog.info(`Ran ${this.testMethods.length} tests`);
        TestLog.info(`\tPASSED: ${successCount}`);
        TestLog.info(`\tFAILED: ${failureCount}`);
        if (failureCount != 0) {
            TestLog.error(`FAILED! One or more tests in ${this.className()} did not pass!`);
        }

        if (this.testDb) {
            return new Promise(function (resolve, _) { this.testDb.close(() => resolve()); }.bind(this));
        } else {
            return Promise.resolve();
        }
    }

    /**
     * Suspend the test server, which will disconnect it from the test config
     * and database, allowing us to reset the server state between tests. */
    async suspend() {
        if (getState() != ServerState.Running) {
            return Promise.resolve();
        }

        return new Promise(function (resolve, _) {
            this.send('suspend').then(_ => {
                TestLog.tmi('Detached from test server');
                resolve();
            }).catch(err => {
                TestLog.error(err, 'Failed to shut down test server cleanly, force stopping tests');
                process.exit(1);
            });
        }.bind(this));
    }

    /**
     * Resumes the test server after being suspended for cleanup. */
    async resume() {
        if (getState() != ServerState.Suspended) {
            return Promise.resolve();
        }

        return new Promise(function(resolve, _) {
            this.send('resume').then(_ => {
                TestLog.tmi('Resuming server');
                resolve();
            }).catch(err => {
                TestLog.error(err, 'Failed to resume server after suspension, force stopping tests');
            });
        }.bind(this));
    }

    /**
     * Send a request to the test server.
     * @param {string} endpoint The command to run
     * @param {*} params Dictionary of query parameters to pass into the test server. */
    async send(endpoint, params={}) {
        if (getState() == ServerState.FirstBoot || getState() == ServerState.ShuttingDown) {
            TestLog.warn('TestHarness: Attempting to send a request to the test server when it isn\'t running!');
            return;
        }

        let url = new URL(`http://localhost:3233/${endpoint}`);
        for (const [key, value] of Object.entries(params)) {
            url.searchParams.append(key, value);
        }

        return fetch(url, { method : 'POST', headers : { accept : 'application/json' } }).then(r => r.json());
    }

    /**
     * Map of default metadata items to their metadata/marker ids. */
    static DefaultMetadata = {
        Show1 : {
            Id : 1,
            Season1 : {
                Id : 2,
                Episode1 : {
                    Id : 3,
                },
                Episode2 : {
                    Id : 4,
                    Marker1 : 1,
                },
                Episode3 : {
                    Id : 5,
                }
            }
        }
    }

    /**
     * Create the minimal recreation of the Plex database and enter some default metadata and marker items. */
    async setupPlexDbTestTables() {
        if (!this.testDb) {
            TestLog.error('Cannot add test marker, database is not initialized!');
            return;
        }

        const tables = TestHelpers.getCreateTables();

        // Create the intro marker tag.
        const introInsert = `INSERT INTO tags (tag_type) VALUES (12);`;

        // Create a single library
        const sectionInsert = `INSERT INTO library_sections (library_id, name, section_type) VALUES (1, "TV", 2);`;

        // For now, create a single show with a single season with a few episodes.
        // TODO: Have a "base" set of shows/seasons/episodes that cover many scenarios, with the option to override
        //       what's added to accommodate any scenario. Also have a map that indicates what's available
        // Type - 2=show, 3=season, 4=episode
        // Index - show=1, everything else = season/episode index
        // inserting id isn't necessary, just helpful for tracking
        const metadataInsert = `
        INSERT INTO metadata_items (id, library_section_id, metadata_type, parent_id, title,       \`index\`)
        VALUES                     (1,  1,                  2,             NULL,      "TV SHOW",   1),
                                   (2,  1,                  3,             1,         "Season 1",  1),
                                   (3,  1,                  4,             2,         "Episode 1", 1),
                                   (4,  1,                  4,             2,         "Episode 2", 2),
                                   (5,  1,                  4,             2,         "Episode 3", 3);`;

        return new Promise(function (resolve, _) {
            this.testDb.exec(tables + introInsert + sectionInsert + metadataInsert + this.defaultMarkers(), (err) => {
                if (err) { throw Error(`Unable to set up test database tables: ${err.message}`); }
                resolve();
            });
        }.bind(this));
    }

    /** @returns The INSERT statements that will add the default markers to the test database. */
    defaultMarkers() {
        const dbMarkerInsert = (metadataId, index, start, end) => `
            INSERT INTO taggings
                (metadata_item_id, tag_id, "index", text, time_offset, end_time_offset, created_at, extra_data)
            VALUES
                (${metadataId}, 1, ${index}, "intro", ${start}, ${end}, CURRENT_TIMESTAMP, "pv%3Aversion=5");`
        return dbMarkerInsert(4, 0, 15000, 45000);
    }

    /**
     * Clear out the test database and re-enter the default data. */
    async resetState() {
        return new Promise(function(resolve, reject) {
            this.testDb.exec(`
                    DELETE FROM taggings;
                    VACUUM;
                    UPDATE sqlite_sequence SET seq=0 WHERE name="taggings";
                    ${this.defaultMarkers()}`,
                (err) => {
                    if (err) { reject(err); return; }
                    resolve();
                }
            );
        }.bind(this));
    }
}

export default TestBase;
